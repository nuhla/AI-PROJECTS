<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Project_Image_Classifier_Project</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="your-first-ai-application" class="cell markdown"
data-colab_type="text" id="y00b5TQZnqs_">
<h1>Your First AI application</h1>
<p>Going forward, AI algorithms will be incorporated into more and more
everyday applications. For example, you might want to include an image
classifier in a smart phone app. To do this, you'd use a deep learning
model trained on hundreds of thousands of images as part of the overall
application architecture. A large part of software development in the
future will be using these types of models as common parts of
applications.</p>
<p>In this project, you'll train an image classifier to recognize
different species of flowers. You can imagine using something like this
in a phone app that tells you the name of the flower your camera is
looking at. In practice you'd train this classifier, then export it for
use in your application. We'll be using <a
href="http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html">this
dataset</a> from Oxford of 102 flower categories, you can see a few
examples below.</p>
<p><img src='assets/Flowers.png' width=500px></p>
<p>The project is broken down into multiple steps:</p>
<ul>
<li>Load the image dataset and create a pipeline.</li>
<li>Build and Train an image classifier on this dataset.</li>
<li>Use your trained model to perform inference on flower images.</li>
</ul>
<p>We'll lead you through each part which you'll implement in
Python.</p>
<p>When you've completed this project, you'll have an application that
can be trained on any set of labeled images. Here your network will be
learning about flowers and end up as a command line application. But,
what you do with your new skills depends on your imagination and effort
in building a dataset. For example, imagine an app where you take a
picture of a car, it tells you what the make and model is, then looks up
information about it. Go build your own dataset and make something
new.</p>
</section>
<section id="import-resources" class="cell markdown"
data-colab_type="text" id="kKnPjnLAftRV">
<h2>Import Resources</h2>
</section>
<div class="cell code" data-execution_count="23" data-colab="{}"
data-colab_type="code" id="2dCk6873paNW">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Make all necessary imports.</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_datasets <span class="im">as</span> tfds</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json <span class="im">as</span> json</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> importlib <span class="im">import</span> <span class="bu">reload</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>plt<span class="op">=</span><span class="bu">reload</span>(plt)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_hub <span class="im">as</span> hub</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<section id="load-the-dataset" class="cell markdown"
data-colab_type="text" id="tWKF0YOarpCx">
<h2>Load the Dataset</h2>
<p>Here you'll use <code>tensorflow_datasets</code> to load the <a
href="https://www.tensorflow.org/datasets/catalog/oxford_flowers102">Oxford
Flowers 102 dataset</a>. This dataset has 3 splits:
<code>'train'</code>, <code>'test'</code>, and
<code>'validation'</code>. You'll also need to make sure the training
data is normalized and resized to 224x224 pixels as required by the
pre-trained networks.</p>
<p>The validation and testing sets are used to measure the model's
performance on data it hasn't seen yet, but you'll still need to
normalize and resize the images to the appropriate size.</p>
</section>
<div class="cell code" data-execution_count="24"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
data-colab_type="code" id="vXISRjfdrrQ6"
data-outputId="6edf59b2-b468-4c4a-cff4-7cc7cfcc3c2d">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Load the dataset with TensorFlow Datasets.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normlize(imge, label):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    imge <span class="op">=</span>tf.cast(imge, tf.float32)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    imge <span class="op">=</span> tf.image.resize(imge,[<span class="dv">224</span>,<span class="dv">224</span>],method<span class="op">=</span><span class="st">&#39;nearest&#39;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    imge<span class="op">/=</span><span class="dv">255</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (imge , label)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>(test,train , validation), summary <span class="op">=</span> tfds.load(<span class="st">&#39;oxford_flowers102&#39;</span>,data_dir<span class="op">=</span><span class="st">&quot;./&quot;</span>, split<span class="op">=</span>[<span class="st">&#39;test&#39;</span>,<span class="st">&#39;train&#39;</span>,<span class="st">&#39;validation&#39;</span>],</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>as_supervised<span class="op">=</span><span class="va">True</span>, with_info<span class="op">=</span><span class="va">True</span>, shuffle_files<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Create a training set, a validation set and a test set.</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span><span class="dv">32</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>Epocs<span class="op">=</span> <span class="dv">15</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co">#train = tf.data.Dataset.from_tensor_slices((y_train , x_train))</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span>train.<span class="bu">map</span>(normlize)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span>test.<span class="bu">map</span>(normlize)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>validation <span class="op">=</span>validation.<span class="bu">map</span>(normlize)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(summary.splits.keys()))</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary.features[<span class="st">&quot;label&quot;</span>].num_classes)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary.features[<span class="st">&quot;label&quot;</span>].names)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>[&#39;train&#39;, &#39;test&#39;, &#39;validation&#39;]
102
[&#39;pink primrose&#39;, &#39;hard-leaved pocket orchid&#39;, &#39;canterbury bells&#39;, &#39;sweet pea&#39;, &#39;english marigold&#39;, &#39;tiger lily&#39;, &#39;moon orchid&#39;, &#39;bird of paradise&#39;, &#39;monkshood&#39;, &#39;globe thistle&#39;, &#39;snapdragon&#39;, &quot;colt&#39;s foot&quot;, &#39;king protea&#39;, &#39;spear thistle&#39;, &#39;yellow iris&#39;, &#39;globe-flower&#39;, &#39;purple coneflower&#39;, &#39;peruvian lily&#39;, &#39;balloon flower&#39;, &#39;giant white arum lily&#39;, &#39;fire lily&#39;, &#39;pincushion flower&#39;, &#39;fritillary&#39;, &#39;red ginger&#39;, &#39;grape hyacinth&#39;, &#39;corn poppy&#39;, &#39;prince of wales feathers&#39;, &#39;stemless gentian&#39;, &#39;artichoke&#39;, &#39;sweet william&#39;, &#39;carnation&#39;, &#39;garden phlox&#39;, &#39;love in the mist&#39;, &#39;mexican aster&#39;, &#39;alpine sea holly&#39;, &#39;ruby-lipped cattleya&#39;, &#39;cape flower&#39;, &#39;great masterwort&#39;, &#39;siam tulip&#39;, &#39;lenten rose&#39;, &#39;barbeton daisy&#39;, &#39;daffodil&#39;, &#39;sword lily&#39;, &#39;poinsettia&#39;, &#39;bolero deep blue&#39;, &#39;wallflower&#39;, &#39;marigold&#39;, &#39;buttercup&#39;, &#39;oxeye daisy&#39;, &#39;common dandelion&#39;, &#39;petunia&#39;, &#39;wild pansy&#39;, &#39;primula&#39;, &#39;sunflower&#39;, &#39;pelargonium&#39;, &#39;bishop of llandaff&#39;, &#39;gaura&#39;, &#39;geranium&#39;, &#39;orange dahlia&#39;, &#39;pink-yellow dahlia?&#39;, &#39;cautleya spicata&#39;, &#39;japanese anemone&#39;, &#39;black-eyed susan&#39;, &#39;silverbush&#39;, &#39;californian poppy&#39;, &#39;osteospermum&#39;, &#39;spring crocus&#39;, &#39;bearded iris&#39;, &#39;windflower&#39;, &#39;tree poppy&#39;, &#39;gazania&#39;, &#39;azalea&#39;, &#39;water lily&#39;, &#39;rose&#39;, &#39;thorn apple&#39;, &#39;morning glory&#39;, &#39;passion flower&#39;, &#39;lotus&#39;, &#39;toad lily&#39;, &#39;anthurium&#39;, &#39;frangipani&#39;, &#39;clematis&#39;, &#39;hibiscus&#39;, &#39;columbine&#39;, &#39;desert-rose&#39;, &#39;tree mallow&#39;, &#39;magnolia&#39;, &#39;cyclamen&#39;, &#39;watercress&#39;, &#39;canna lily&#39;, &#39;hippeastrum&#39;, &#39;bee balm&#39;, &#39;ball moss&#39;, &#39;foxglove&#39;, &#39;bougainvillea&#39;, &#39;camellia&#39;, &#39;mallow&#39;, &#39;mexican petunia&#39;, &#39;bromelia&#39;, &#39;blanket flower&#39;, &#39;trumpet creeper&#39;, &#39;blackberry lily&#39;]
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="25">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> train.take(<span class="dv">1</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> example <span class="kw">in</span> ds:  <span class="co"># example is `{&#39;image&#39;: tf.Tensor, &#39;label&#39;: tf.Tensor}`</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#print(list(example.keys()))</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="bu">len</span>(example))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  image <span class="op">=</span> example[<span class="dv">0</span>].numpy()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#file_name = example[&quot;file_name&quot;]</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  label <span class="op">=</span> example[<span class="dv">1</span>].numpy()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(label)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>2
72
</code></pre>
</div>
</div>
<section id="explore-the-dataset" class="cell markdown"
data-colab_type="text" id="S5pdQnDbf0-j">
<h2>Explore the Dataset</h2>
</section>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:102}"
data-colab_type="code" id="XikJ4X7FUv8v"
data-outputId="10240009-1148-41ae-8ce0-4025c2f2fa87">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Get the number of examples in each set from the dataset info.</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>length_train <span class="op">=</span> summary.splits[<span class="st">&#39;train&#39;</span>].num_examples</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>length_test <span class="op">=</span>  summary.splits[<span class="st">&#39;test&#39;</span>].num_examples</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>length_val <span class="op">=</span> summary.splits[<span class="st">&#39;validation&#39;</span>].num_examples</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Train Number of Examples =&quot;</span>, length_train)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Number of Examples =&quot;</span>, length_test)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation Number of Examples =&quot;</span>, <span class="bu">str</span>(length_val))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># done: Get the number of classes in the dataset from the dataset info.</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>class_num <span class="op">=</span> <span class="bu">len</span>(summary.features[<span class="st">&#39;label&#39;</span>].names)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Number of classes is :&quot;</span>,class_num)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train Number of Examples = 1020
Test Number of Examples = 6149
Validation Number of Examples = 1020
Number of classes is : 102
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:68}"
data-colab_type="code" id="CWR9ScCbPI_D"
data-outputId="fdf01c8d-2db9-4d7c-a566-4db2599fd1ab">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Print the shape and corresponding label of 3 images in the training set.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>train_ds<span class="op">=</span>train.take(<span class="dv">3</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> train_ds:</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span>row[<span class="dv">0</span>]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span>row[<span class="dv">1</span>]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Shape         name&quot;</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(image.shape, summary.features[<span class="st">&#39;label&#39;</span>].names[label.numpy()])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Shape         name
(224, 224, 3) water lily
Shape         name
(224, 224, 3) desert-rose
Shape         name
(224, 224, 3) gazania
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="28"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:280}"
data-colab_type="code" id="DQbnq8htRTnl"
data-outputId="32a0e1af-2b04-440e-ddb4-835732be3e83">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Plot 1 image from the training set. Set the title </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># of the plot to the corresponding image label. </span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>img_ds <span class="op">=</span> train.take(<span class="dv">1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>name <span class="op">=</span><span class="st">&quot;&quot;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> img_ds :</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span>col[<span class="dv">0</span>]</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> col[<span class="dv">1</span>].numpy()</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    plt.imshow(image)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    plt.title(name , {<span class="st">&quot;size&quot;</span>:<span class="dv">20</span>,<span class="st">&quot;color&quot;</span>:<span class="st">&quot;blue&quot;</span> })</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output display_data">
<p><img
src="Project_Image_Classifier_Project/12b36f0e397d5f7a0aa70c1ab2e43693a92b38e4.png" /></p>
</div>
</div>
<section id="label-mapping" class="cell markdown" data-colab_type="text"
id="zuh1841cs-j1">
<h3>Label Mapping</h3>
<p>You'll also need to load in a mapping from label to category name.
You can find this in the file <code>label_map.json</code>. It's a JSON
object which you can read in with the <a
href="https://docs.python.org/3.7/library/json.html"><code>json</code>
module</a>. This will give you a dictionary mapping the integer coded
labels to the actual names of the flowers.</p>
</section>
<div class="cell code" data-execution_count="29" data-colab="{}"
data-colab_type="code" id="JoVzdO3KsdSk">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&#39;label_map.json&#39;</span>, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    class_names <span class="op">=</span> json.load(f)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="30"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:280}"
data-colab_type="code" id="fc6pMUZgEvUo"
data-outputId="4274fd43-5cee-4523-885f-a18f6f277dd6">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Plot 1 image from the training set. Set the title </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># of the plot to the corresponding class name. </span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>img_ds <span class="op">=</span> train.take(<span class="dv">1</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>name <span class="op">=</span><span class="st">&quot;&quot;</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> img_ds :</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span>col[<span class="dv">0</span>]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>name <span class="op">=</span> col[<span class="dv">1</span>].numpy()</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.imshow(image)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.title(class_names[<span class="bu">str</span>(name)] , {<span class="st">&quot;size&quot;</span>:<span class="dv">20</span>,<span class="st">&quot;color&quot;</span>:<span class="st">&quot;blue&quot;</span> })</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output execute_result" data-execution_count="30">
<pre><code>Text(0.5, 1.0, &#39;water lily&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="Project_Image_Classifier_Project/307752fc0e353fcafffda5706fb46ae5e0860553.png" /></p>
</div>
</div>
<section id="create-pipeline" class="cell markdown"
data-colab_type="text" id="0gL7AaqNf-NC">
<h2>Create Pipeline</h2>
</section>
<div class="cell code" data-execution_count="31"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:88}"
data-colab_type="code" id="5hNznLbPNZxS"
data-outputId="7c114910-b75f-4220-cda9-f84426ec2728">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Create a pipeline for each set.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>swap_train <span class="op">=</span> train </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> test</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> swap_train</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>train<span class="op">=</span>train.cache().shuffle(length_train<span class="op">//</span><span class="dv">4</span>).batch(batch_size,drop_remainder<span class="op">=</span><span class="va">True</span>).prefetch(<span class="dv">1</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> test.cache().shuffle(length_test<span class="op">//</span><span class="dv">4</span>).batch(batch_size,drop_remainder<span class="op">=</span><span class="va">True</span>).prefetch(<span class="dv">1</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>validation <span class="op">=</span> validation.cache().shuffle(length_val<span class="op">//</span><span class="dv">4</span>).batch(batch_size,drop_remainder<span class="op">=</span><span class="va">True</span>).prefetch(<span class="dv">1</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(validation)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(32, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32,), dtype=tf.int64, name=None))&gt;
&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(32, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32,), dtype=tf.int64, name=None))&gt;
&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(32, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(32,), dtype=tf.int64, name=None))&gt;
</code></pre>
</div>
</div>
<section id="build-and-train-the-classifier" class="cell markdown"
data-colab_type="text" id="gR9gtRbeXPYx">
<h1>Build and Train the Classifier</h1>
<p>Now that the data is ready, it's time to build and train the
classifier. You should use the MobileNet pre-trained model from
TensorFlow Hub to get the image features. Build and train a new
feed-forward classifier using those features.</p>
<p>We're going to leave this part up to you. If you want to talk through
it with someone, chat with your fellow students!</p>
<p>Refer to the rubric for guidance on successfully completing this
section. Things you'll need to do:</p>
<ul>
<li>Load the MobileNet pre-trained network from TensorFlow Hub.</li>
<li>Define a new, untrained feed-forward network as a classifier.</li>
<li>Train the classifier.</li>
<li>Plot the loss and accuracy values achieved during training for the
training and validation set.</li>
<li>Save your trained model as a Keras model.</li>
</ul>
<p>We've left a cell open for you below, but use as many as you need.
Our advice is to break the problem up into smaller parts you can run
separately. Check that each part is doing what you expect, then move on
to the next. You'll likely find that as you work through each part,
you'll need to go back and modify your previous code. This is totally
normal!</p>
<p>When training make sure you're updating only the weights of the
feed-forward network. You should be able to get the validation accuracy
above 70% if you build everything right.</p>
<p><strong>Note for Workspace users:</strong> One important tip if
you're using the workspace to run your code: To avoid having your
workspace disconnect during the long-running tasks in this notebook,
please read in the earlier page in this lesson called Intro to GPU
Workspaces about Keeping Your Session Active. You'll want to include
code from the workspace_utils.py module. Also, If your model is over 1
GB when saved as a checkpoint, there might be issues with saving backups
in your workspace. If your saved checkpoint is larger than 1 GB (you can
open a terminal and check with <code>ls -lh</code>), you should reduce
the size of your hidden layers and train again.</p>
</section>
<div class="cell code" data-execution_count="32" data-colab="{}"
data-colab_type="code" id="4zElEHViXLni">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># # DONE: Build and train your network.</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># after searching this is the couse to do version investagtion </span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Depending on the Keras version, the module might either import tf_keras or</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># directly use tf.keras, the former causes the isinstance(layer, Layer) </span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># check in Sequential.add to return False for hub.KerasLayer, even though it</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   inherits from keras.layers.Layer</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>version_fn <span class="op">=</span> <span class="bu">getattr</span>(tf.keras, <span class="st">&quot;version&quot;</span>, <span class="va">None</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> version_fn <span class="kw">and</span> version_fn().startswith(<span class="st">&quot;3.&quot;</span>):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> tf_keras <span class="im">as</span> keras</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  keras <span class="op">=</span> tf.keras</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> keras.Sequential([</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    hub.KerasLayer(<span class="st">&quot;https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/tf2-preview-feature-vector/4&quot;</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    , output_shape<span class="op">=</span>[<span class="dv">1280</span>],</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    trainable<span class="op">=</span><span class="va">False</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>                     ),</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.2</span>),</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">640</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.4</span>),</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">320</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.2</span>),</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    layers.Dense(class_num, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>m.build([<span class="va">None</span>, <span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>])  <span class="co"># Batch input shape.</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>callback <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">&#39;val_loss&#39;</span>,</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>                                              patience<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>checkpoint_path <span class="op">=</span> <span class="st">&quot;training_1/cp.ckpt&quot;</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>checkpoint_dir <span class="op">=</span> os.path.dirname(checkpoint_path)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a callback that saves the model&#39;s weights</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>cp_callback <span class="op">=</span> tf.keras.callbacks.ModelCheckpoint(filepath<span class="op">=</span>checkpoint_path,</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>                                                 save_weights_only<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>                                                 save_best_only <span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>                                                 verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>m.summary(expand_nested<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 keras_layer (KerasLayer)    (None, 1280)              2257984   
                                                                 
 dropout (Dropout)           (None, 1280)              0         
                                                                 
 dense (Dense)               (None, 640)               819840    
                                                                 
 dropout_1 (Dropout)         (None, 640)               0         
                                                                 
 dense_1 (Dense)             (None, 320)               205120    
                                                                 
 dropout_2 (Dropout)         (None, 320)               0         
                                                                 
 dense_2 (Dense)             (None, 102)               32742     
                                                                 
=================================================================
Total params: 3315686 (12.65 MB)
Trainable params: 1057702 (4.03 MB)
Non-trainable params: 2257984 (8.61 MB)
_________________________________________________________________
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="33">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>m.<span class="bu">compile</span>(loss<span class="op">=</span>tf.keras.losses.SparseCategoricalCrossentropy(),</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>           optimizer<span class="op">=</span>tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">.0005</span>),</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>             metrics<span class="op">=</span>[tf.keras.metrics.SparseCategoricalAccuracy()])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="34">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>Epocs<span class="op">=</span> <span class="dv">15</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> m.fit(train,  validation_data<span class="op">=</span>validation,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                 epochs<span class="op">=</span>Epocs, batch_size<span class="op">=</span>batch_size,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                  callbacks<span class="op">=</span>[callback,cp_callback])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/15
192/192 [==============================] - ETA: 0s - loss: 3.0910 - sparse_categorical_accuracy: 0.3203
Epoch 1: val_loss improved from inf to 1.79705, saving model to training_1\cp.ckpt
192/192 [==============================] - 153s 775ms/step - loss: 3.0910 - sparse_categorical_accuracy: 0.3203 - val_loss: 1.7970 - val_sparse_categorical_accuracy: 0.5333
Epoch 2/15
192/192 [==============================] - ETA: 0s - loss: 1.3840 - sparse_categorical_accuracy: 0.6364
Epoch 2: val_loss improved from 1.79705 to 0.94045, saving model to training_1\cp.ckpt
192/192 [==============================] - 138s 719ms/step - loss: 1.3840 - sparse_categorical_accuracy: 0.6364 - val_loss: 0.9405 - val_sparse_categorical_accuracy: 0.7571
Epoch 3/15
192/192 [==============================] - ETA: 0s - loss: 0.9089 - sparse_categorical_accuracy: 0.7412
Epoch 3: val_loss improved from 0.94045 to 0.70875, saving model to training_1\cp.ckpt
192/192 [==============================] - 134s 698ms/step - loss: 0.9089 - sparse_categorical_accuracy: 0.7412 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.8044
Epoch 4/15
192/192 [==============================] - ETA: 0s - loss: 0.6685 - sparse_categorical_accuracy: 0.8026
Epoch 4: val_loss improved from 0.70875 to 0.56198, saving model to training_1\cp.ckpt
192/192 [==============================] - 134s 700ms/step - loss: 0.6685 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.8327
Epoch 5/15
192/192 [==============================] - ETA: 0s - loss: 0.5524 - sparse_categorical_accuracy: 0.8332
Epoch 5: val_loss improved from 0.56198 to 0.49847, saving model to training_1\cp.ckpt
192/192 [==============================] - 151s 787ms/step - loss: 0.5524 - sparse_categorical_accuracy: 0.8332 - val_loss: 0.4985 - val_sparse_categorical_accuracy: 0.8659
Epoch 6/15
192/192 [==============================] - ETA: 0s - loss: 0.4410 - sparse_categorical_accuracy: 0.8698
Epoch 6: val_loss improved from 0.49847 to 0.45897, saving model to training_1\cp.ckpt
192/192 [==============================] - 139s 725ms/step - loss: 0.4410 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.4590 - val_sparse_categorical_accuracy: 0.8679
Epoch 7/15
192/192 [==============================] - ETA: 0s - loss: 0.3919 - sparse_categorical_accuracy: 0.8830
Epoch 7: val_loss did not improve from 0.45897
192/192 [==============================] - 139s 725ms/step - loss: 0.3919 - sparse_categorical_accuracy: 0.8830 - val_loss: 0.4694 - val_sparse_categorical_accuracy: 0.8730
Epoch 8/15
192/192 [==============================] - ETA: 0s - loss: 0.3210 - sparse_categorical_accuracy: 0.9038
Epoch 8: val_loss improved from 0.45897 to 0.41656, saving model to training_1\cp.ckpt
192/192 [==============================] - 140s 729ms/step - loss: 0.3210 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.4166 - val_sparse_categorical_accuracy: 0.8810
Epoch 9/15
192/192 [==============================] - ETA: 0s - loss: 0.3037 - sparse_categorical_accuracy: 0.9064
Epoch 9: val_loss improved from 0.41656 to 0.40551, saving model to training_1\cp.ckpt
192/192 [==============================] - 140s 732ms/step - loss: 0.3037 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.4055 - val_sparse_categorical_accuracy: 0.8861
Epoch 10/15
192/192 [==============================] - ETA: 0s - loss: 0.2517 - sparse_categorical_accuracy: 0.9219
Epoch 10: val_loss improved from 0.40551 to 0.39021, saving model to training_1\cp.ckpt
192/192 [==============================] - 140s 730ms/step - loss: 0.2517 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.3902 - val_sparse_categorical_accuracy: 0.8921
Epoch 11/15
192/192 [==============================] - ETA: 0s - loss: 0.2413 - sparse_categorical_accuracy: 0.9240
Epoch 11: val_loss did not improve from 0.39021
192/192 [==============================] - 140s 728ms/step - loss: 0.2413 - sparse_categorical_accuracy: 0.9240 - val_loss: 0.3945 - val_sparse_categorical_accuracy: 0.8841
Epoch 12/15
192/192 [==============================] - ETA: 0s - loss: 0.2035 - sparse_categorical_accuracy: 0.9362
Epoch 12: val_loss did not improve from 0.39021
192/192 [==============================] - 140s 730ms/step - loss: 0.2035 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.3911 - val_sparse_categorical_accuracy: 0.8871
Epoch 13/15
192/192 [==============================] - ETA: 0s - loss: 0.1828 - sparse_categorical_accuracy: 0.9417
Epoch 13: val_loss improved from 0.39021 to 0.38249, saving model to training_1\cp.ckpt
192/192 [==============================] - 141s 734ms/step - loss: 0.1828 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3825 - val_sparse_categorical_accuracy: 0.8810
Epoch 14/15
192/192 [==============================] - ETA: 0s - loss: 0.1898 - sparse_categorical_accuracy: 0.9375
Epoch 14: val_loss did not improve from 0.38249
192/192 [==============================] - 140s 732ms/step - loss: 0.1898 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.4202 - val_sparse_categorical_accuracy: 0.8891
Epoch 15/15
192/192 [==============================] - ETA: 0s - loss: 0.1921 - sparse_categorical_accuracy: 0.9378
Epoch 15: val_loss improved from 0.38249 to 0.35857, saving model to training_1\cp.ckpt
192/192 [==============================] - 144s 748ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9378 - val_loss: 0.3586 - val_sparse_categorical_accuracy: 0.9062
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="35"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:498}"
data-colab_type="code" id="VU6sWzx4e7Yb"
data-outputId="f7b5c7c5-683a-463c-9228-68c4918bdd5b">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Plot the loss and accuracy values achieved during training for the training and validation set.</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize history for accuracy</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;sparse_categorical_accuracy&#39;</span>])</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_sparse_categorical_accuracy&#39;</span>])</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;model accuracy&#39;</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;sparse_categorical_accuracy&#39;</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;epoch&#39;</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">&#39;Train&#39;</span>, <span class="st">&#39;Validation&#39;</span>], loc<span class="op">=</span><span class="st">&#39;upper left&#39;</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize history for loss</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>])</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>])</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;model loss&#39;</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;loss&#39;</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;epoch&#39;</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">&#39;Train&#39;</span>, <span class="st">&#39;Validation&#39;</span>], loc<span class="op">=</span><span class="st">&#39;upper left&#39;</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="Project_Image_Classifier_Project/6c5db29c38054661a6e9e680d37bb50ede5b2450.png" /></p>
</div>
<div class="output display_data">
<p><img
src="Project_Image_Classifier_Project/42c620f8396ac8478c4769fa2b62e9000af5aeae.png" /></p>
</div>
</div>
<section id="testing-your-network" class="cell markdown"
data-colab_type="text" id="qcTDnyvop3ky">
<h2>Testing your Network</h2>
<p>It's good practice to test your trained network on test data, images
the network has never seen either in training or validation. This will
give you a good estimate for the model's performance on completely new
images. You should be able to reach around 70% accuracy on the test set
if the model has been trained well.</p>
</section>
<div class="cell code" data-execution_count="36"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:85}"
data-colab_type="code" id="79l7-HM1cafO"
data-outputId="6cf468a4-1e27-4f20-d63a-a8bdd78bcdbe">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Print the loss and accuracy values achieved on the entire test set.</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> m.evaluate(test,verbose<span class="op">=</span><span class="dv">2</span> )</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="bu">dict</span>(<span class="bu">zip</span>(m.metrics_names, score))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>31/31 - 18s - loss: 0.4548 - sparse_categorical_accuracy: 0.8770 - 18s/epoch - 588ms/step
</code></pre>
</div>
<div class="output execute_result" data-execution_count="36">
<pre><code>{&#39;loss&#39;: 0.45484083890914917,
 &#39;sparse_categorical_accuracy&#39;: 0.8770161271095276}</code></pre>
</div>
</div>
<section id="save-the-model" class="cell markdown"
data-colab_type="text" id="pLsIDWnuqfkl">
<h2>Save the Model</h2>
<p>Now that your network is trained, save the model so you can load it
later for making inference. In the cell below save your model as a Keras
model (<em>i.e.</em> save it as an HDF5 file).</p>
</section>
<div class="cell code" data-execution_count="37" data-colab="{}"
data-colab_type="code" id="7XOwdOjSptp-">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Save your trained model as a Keras model.</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>saved_h5_model_filepath <span class="op">=</span><span class="st">&#39;./models/flowerClassification.h5&#39;</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>saved_h5_wights_filepath <span class="op">=</span><span class="st">&#39;./wights/flowerClassification.h5&#39;</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>m.save(saved_h5_model_filepath)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>m.save_weights(saved_h5_wights_filepath, overwrite<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>d:\PythonProjects\deepcnn Image clasif\classifVnv\lib\site-packages\keras\src\engine\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save(&#39;my_model.keras&#39;)`.
  saving_api.save_model(
</code></pre>
</div>
</div>
<section id="load-the-keras-model" class="cell markdown"
data-colab_type="text" id="rbeLSRC1rxuj">
<h2>Load the Keras Model</h2>
<p>Load the Keras model you saved above.</p>
</section>
<div class="cell code" data-execution_count="38"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:394}"
data-colab_type="code" id="3T6Dgc7Nrzds"
data-outputId="f5d356dc-183f-4cd3-f15d-88ebb4966082">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Load the Keras model</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>reloaded_h5_model <span class="op">=</span>tf.keras.models.load_model(saved_h5_model_filepath,  <span class="bu">compile</span> <span class="op">=</span> <span class="va">True</span>, custom_objects<span class="op">=</span>{<span class="st">&#39;KerasLayer&#39;</span>:hub.KerasLayer}) </span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>reloaded_h5_model.load_weights(saved_h5_wights_filepath)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># test model </span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------- # </span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">#-----------------normlize image -------------------#</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------------------------------------#</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>imge <span class="op">=</span> Image.<span class="bu">open</span>(<span class="st">&quot;./test_images/hard-leaved_pocket_orchid.jpg&quot;</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>imge <span class="op">=</span>tf.cast(imge, tf.float32)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>imge <span class="op">=</span> tf.image.resize(imge,[<span class="dv">224</span>,<span class="dv">224</span>],method<span class="op">=</span><span class="st">&#39;nearest&#39;</span>)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>imge<span class="op">/=</span><span class="dv">255</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>new_image_batch <span class="op">=</span> np.stack((imge,), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span>reloaded_h5_model.predict(new_image_batch)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>top_k_values, top_k_indices <span class="op">=</span> tf.nn.top_k(<span class="bu">list</span>(tf.cast(outputs, tf.float32)), k<span class="op">=</span><span class="dv">5</span>,)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_k_values)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Predictions : &quot;</span>, top_k_indices.numpy()[<span class="dv">0</span>])</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;top prediction Name : &quot;</span>,class_names[<span class="bu">str</span>(top_k_indices.numpy()[<span class="dv">0</span>][<span class="dv">0</span>])])</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>1/1 [==============================] - 1s 518ms/step
tf.Tensor([[9.9999797e-01 1.5430402e-06 1.8651734e-07 1.0666022e-07 3.5736718e-08]], shape=(1, 5), dtype=float32)
Predictions :  [ 1 79  5 17 19]
top prediction Name :  hard-leaved pocket orchid
</code></pre>
</div>
</div>
<section id="inference-for-classification" class="cell markdown"
data-colab_type="text" id="ZjucwuFrsyhJ">
<h1>Inference for Classification</h1>
<p>Now you'll write a function that uses your trained network for
inference. Write a function called <code>predict</code> that takes an
image, a model, and then returns the top <span
class="math inline"><em>K</em></span> most likely class labels along
with the probabilities. The function call should look like:</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>probs, classes <span class="op">=</span> predict(image_path, model, top_k)</span></code></pre></div>
<p>If <code>top_k=5</code> the output of the <code>predict</code>
function should be something like this:</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>probs, classes <span class="op">=</span> predict(image_path, model, <span class="dv">5</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(probs)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classes)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> [ <span class="fl">0.01558163</span>  <span class="fl">0.01541934</span>  <span class="fl">0.01452626</span>  <span class="fl">0.01443549</span>  <span class="fl">0.01407339</span>]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> [<span class="st">&#39;70&#39;</span>, <span class="st">&#39;3&#39;</span>, <span class="st">&#39;45&#39;</span>, <span class="st">&#39;62&#39;</span>, <span class="st">&#39;55&#39;</span>]</span></code></pre></div>
<p>Your <code>predict</code> function should use <code>PIL</code> to
load the image from the given <code>image_path</code>. You can use the
<a
href="https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.open">Image.open</a>
function to load the images. The <code>Image.open()</code> function
returns an <code>Image</code> object. You can convert this
<code>Image</code> object to a NumPy array by using the
<code>np.asarray()</code> function.</p>
<p>The <code>predict</code> function will also need to handle
pre-processing the input image such that it can be used by your model.
We recommend you write a separate function called
<code>process_image</code> that performs the pre-processing. You can
then call the <code>process_image</code> function from the
<code>predict</code> function.</p>
<h3 id="image-pre-processing">Image Pre-processing</h3>
<p>The <code>process_image</code> function should take in an image (in
the form of a NumPy array) and return an image in the form of a NumPy
array with shape <code>(224, 224, 3)</code>.</p>
<p>First, you should convert your image into a TensorFlow Tensor and
then resize it to the appropriate size using
<code>tf.image.resize</code>.</p>
<p>Second, the pixel values of the input images are typically encoded as
integers in the range 0-255, but the model expects the pixel values to
be floats in the range 0-1. Therefore, you'll also need to normalize the
pixel values.</p>
<p>Finally, convert your image back to a NumPy array using the
<code>.numpy()</code> method.</p>
</section>
<div class="cell code" data-execution_count="39" data-colab="{}"
data-colab_type="code" id="oG7mJ1-5s1qe">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Create the process_image function</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_image(image):</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ------------------------------------------------- # </span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#-----------------normlize image -------------------#</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#---------------------------------------------------#</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span>tf.cast(image, tf.float32)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.resize(image,[<span class="dv">224</span>,<span class="dv">224</span>],method<span class="op">=</span><span class="st">&#39;nearest&#39;</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    image<span class="op">/=</span><span class="dv">255</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> image.numpy()</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell markdown">
<p>To check your <code>process_image</code> function we have provided 4
images in the <code>./test_images/</code> folder:</p>
<ul>
<li>cautleya_spicata.jpg</li>
<li>hard-leaved_pocket_orchid.jpg</li>
<li>orange_dahlia.jpg</li>
<li>wild_pansy.jpg</li>
</ul>
<p>The code below loads one of the above images using <code>PIL</code>
and plots the original image alongside the image produced by your
<code>process_image</code> function. If your <code>process_image</code>
function works, the plotted image should be the correct size.</p>
</div>
<div class="cell code" data-execution_count="40">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> <span class="st">&#39;./test_images/hard-leaved_pocket_orchid.jpg&#39;</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> Image.<span class="bu">open</span>(image_path)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>test_image <span class="op">=</span> np.asarray(im)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>processed_test_image <span class="op">=</span> process_image(test_image)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>), ncols<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>ax1.imshow(test_image)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Original Image&#39;</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>ax2.imshow(processed_test_image)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;Processed Image&#39;</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="Project_Image_Classifier_Project/90883fd1008cf36269ab46aeb0775e8dde545308.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>Once you can get images in the correct format, it's time to write the
<code>predict</code> function for making inference with your model.</p>
<h3 id="inference">Inference</h3>
<p>Remember, the <code>predict</code> function should take an image, a
model, and then returns the top <span
class="math inline"><em>K</em></span> most likely class labels along
with the probabilities. The function call should look like:</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>probs, classes <span class="op">=</span> predict(image_path, model, top_k)</span></code></pre></div>
<p>If <code>top_k=5</code> the output of the <code>predict</code>
function should be something like this:</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>probs, classes <span class="op">=</span> predict(image_path, model, <span class="dv">5</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(probs)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classes)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> [ <span class="fl">0.01558163</span>  <span class="fl">0.01541934</span>  <span class="fl">0.01452626</span>  <span class="fl">0.01443549</span>  <span class="fl">0.01407339</span>]</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> [<span class="st">&#39;70&#39;</span>, <span class="st">&#39;3&#39;</span>, <span class="st">&#39;45&#39;</span>, <span class="st">&#39;62&#39;</span>, <span class="st">&#39;55&#39;</span>]</span></code></pre></div>
<p>Your <code>predict</code> function should use <code>PIL</code> to
load the image from the given <code>image_path</code>. You can use the
<a
href="https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.open">Image.open</a>
function to load the images. The <code>Image.open()</code> function
returns an <code>Image</code> object. You can convert this
<code>Image</code> object to a NumPy array by using the
<code>np.asarray()</code> function.</p>
<p><strong>Note:</strong> The image returned by the
<code>process_image</code> function is a NumPy array with shape
<code>(224, 224, 3)</code> but the model expects the input images to be
of shape <code>(1, 224, 224, 3)</code>. This extra dimension represents
the batch size. We suggest you use the <code>np.expand_dims()</code>
function to add the extra dimension.</p>
</div>
<div class="cell code" data-execution_count="41" data-colab="{}"
data-colab_type="code" id="SBnPKFJuGB32">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Create the predict function</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(image_path,model,topk<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     #---------------------------------------------------#</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     #------------------Process Image -------------------#</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     #---------------------------------------------------#</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    imge <span class="op">=</span> Image.<span class="bu">open</span>(image_path)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    imge <span class="op">=</span> process_image(imge)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    new_image_batch <span class="op">=</span> np.stack((imge,), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co">#     #---------------------------------------------------#</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co">#     #---------------------Load Model -------------------#</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     #---------------------------------------------------#</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    KeraseHublayer<span class="op">=</span>tf.keras.models.load_model(<span class="st">&quot;./models/&quot;</span><span class="op">+</span>model,  <span class="bu">compile</span> <span class="op">=</span> <span class="va">True</span>, custom_objects<span class="op">=</span>{<span class="st">&#39;KerasLayer&#39;</span>:hub.KerasLayer}) </span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    KeraseHublayer.load_weights(<span class="st">&quot;./wights/&quot;</span><span class="op">+</span>model)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co">#     #---------------------------------------------------#</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co">#     #------------------Predict Image -------------------#</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co">#     #---------------------------------------------------#</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span>KeraseHublayer.predict(new_image_batch)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    top_k_values, top_k_indices <span class="op">=</span> tf.nn.top_k(<span class="bu">list</span>(tf.cast(outputs, tf.float32)), k<span class="op">=</span>topk)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>  top_k_values.numpy()[<span class="dv">0</span>], top_k_indices[<span class="dv">0</span>].numpy()</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="co">#predict(&#39;./test_images/hard-leaved_pocket_orchid.jpg&#39;,&quot;imageclassifier.hdf5&quot;)</span></span></code></pre></div>
</div>
<section id="sanity-check" class="cell markdown" data-colab_type="text"
id="aft8f_n5C7Co">
<h1>Sanity Check</h1>
<p>It's always good to check the predictions made by your model to make
sure they are correct. To check your predictions we have provided 4
images in the <code>./test_images/</code> folder:</p>
<ul>
<li>cautleya_spicata.jpg</li>
<li>hard-leaved_pocket_orchid.jpg</li>
<li>orange_dahlia.jpg</li>
<li>wild_pansy.jpg</li>
</ul>
<p>In the cell below use <code>matplotlib</code> to plot the input image
alongside the probabilities for the top 5 classes predicted by your
model. Plot the probabilities as a bar graph. The plot should look like
this:</p>
<p><img src='assets/inference_example.png' width=600px></p>
<p>You can convert from the class integer labels to actual flower names
using <code>class_names</code>.</p>
</section>
<div class="cell code" data-execution_count="42"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:336}"
data-colab_type="code" id="I_tBH8xGGVxQ"
data-outputId="ef0fe795-65f3-49c5-fab0-086fac7d409d">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DONE: Plot the input image along with the top 5 classes</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span><span class="st">&quot;./test_images/&quot;</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>image_name<span class="op">=</span> <span class="st">&quot;hard-leaved_pocket_orchid.jpg&quot;</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> img_path<span class="op">+</span>image_name</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># model =&quot;./models/&quot;</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>top_k <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>props, classes <span class="op">=</span> predict(image,<span class="st">&#39;flowerClassification.h5&#39;</span>,top_k)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>class_labels<span class="op">=</span> []</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> class_value <span class="kw">in</span> classes :</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    class_labels.append(class_names[<span class="bu">str</span>(class_value)])</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Load image</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> Image.<span class="bu">open</span>(image)</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>image<span class="op">=</span>process_image(image)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Get top 5 probabilities and class labels</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> np.array(props)</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> np.array(class_labels)</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subplots</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">5</span>))</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Display image</span></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].imshow(image)</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(image_name)</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Create bar graph</span></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>values_bar <span class="op">=</span> axs[<span class="dv">1</span>].barh(class_labels, probabilities, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;Probability&#39;</span>)</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;Class&#39;</span>)</span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">&#39;Top 5 Predictions&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>1/1 [==============================] - 1s 528ms/step
</code></pre>
</div>
<div class="output execute_result" data-execution_count="42">
<pre><code>Text(0.5, 1.0, &#39;Top 5 Predictions&#39;)</code></pre>
</div>
<div class="output display_data">
<p><img
src="Project_Image_Classifier_Project/972ac0600ea3c7fb31f200bab43af37daa808992.png" /></p>
</div>
</div>
</body>
</html>
